<?xml version="1.0" encoding="UTF-8"?>
<testsuite name="com.klarna.hiverunner.ResourceOutputStreamTest" tests="3" skipped="0" failures="1" errors="0" timestamp="2015-09-09T16:11:04" hostname="Himanshu.local" time="0.693">
  <properties/>
  <testcase name="sequenceFile" classname="com.klarna.hiverunner.ResourceOutputStreamTest" time="0.199">
    <failure message="java.lang.IllegalStateException: Failed to reset to default schema: Query returned non-zero code: 1, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Database does not exist: default" type="java.lang.IllegalStateException">java.lang.IllegalStateException: Failed to reset to default schema: Query returned non-zero code: 1, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Database does not exist: default
	at com.klarna.hiverunner.HiveServerContainer.tearDown(HiveServerContainer.java:121)
	at com.klarna.hiverunner.builder.HiveShellTearable.tearDown(HiveShellTearable.java:41)
	at com.klarna.hiverunner.StandaloneHiveRunner.evaluateStatement(StandaloneHiveRunner.java:106)
	at com.klarna.hiverunner.StandaloneHiveRunner.access$000(StandaloneHiveRunner.java:53)
	at com.klarna.hiverunner.StandaloneHiveRunner$1$1.evaluate(StandaloneHiveRunner.java:79)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:64)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:50)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)
	at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)
	at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:360)
	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54)
	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: HiveServerException(message:Query returned non-zero code: 1, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Database does not exist: default, errorCode:1, SQLState:08S01)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:218)
	at com.klarna.hiverunner.HiveServerContainer.tearDown(HiveServerContainer.java:119)
	... 41 more
</failure>
  </testcase>
  <testcase name="writeShouldOnlyBeAllowedBeforeStartHasBeenCalled" classname="com.klarna.hiverunner.ResourceOutputStreamTest" time="0.204"/>
  <testcase name="itShouldBePossibleToAddAResourceByOutputStream" classname="com.klarna.hiverunner.ResourceOutputStreamTest" time="0.29"/>
  <system-out><![CDATA[]]></system-out>
  <system-err><![CDATA[15/09/09 11:11:04 INFO metastore.HiveMetaStore: No user is added in admin role, since config is empty
15/09/09 11:11:04 INFO metastore.HiveMetaStore: 0: Shutting down the object store...
15/09/09 11:11:04 INFO HiveMetaStore.audit: ugi=hpatel	ip=unknown-ip-addr	cmd=Shutting down the object store...	
15/09/09 11:11:04 INFO metastore.HiveMetaStore: 0: Metastore shutdown complete.
15/09/09 11:11:04 INFO HiveMetaStore.audit: ugi=hpatel	ip=unknown-ip-addr	cmd=Metastore shutdown complete.	
15/09/09 11:11:04 INFO metastore.HiveMetaStore: No user is added in admin role, since config is empty
15/09/09 11:11:04 INFO session.SessionState: No Tez session required at this point. hive.execution.engine=mr.
15/09/09 11:11:04 INFO service.HiveServer: Putting temp output to file /var/folders/y7/4_pz5fzx54ngcmghz3v6t3m00000gn/T/junit7833263551662758268/localscratchdir/ea3e7871-018e-445c-9218-af1c67b370d06283822568831367851.pipeout
15/09/09 11:11:04 INFO service.HiveServer: Running the query: SHOW TABLES
15/09/09 11:11:04 INFO log.PerfLogger: <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:04 INFO log.PerfLogger: <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:04 INFO ql.Driver: Concurrency mode is disabled, not creating a lock manager
15/09/09 11:11:04 INFO log.PerfLogger: <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:04 INFO log.PerfLogger: <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:04 INFO parse.ParseDriver: Parsing command: SHOW TABLES
15/09/09 11:11:04 INFO parse.ParseDriver: Parse Completed
15/09/09 11:11:04 INFO log.PerfLogger: </PERFLOG method=parse start=1441815064884 end=1441815064884 duration=0 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:04 INFO log.PerfLogger: <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:04 INFO ql.Driver: Semantic Analysis Completed
15/09/09 11:11:04 INFO log.PerfLogger: </PERFLOG method=semanticAnalyze start=1441815064884 end=1441815064888 duration=4 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:04 INFO exec.ListSinkOperator: Initializing Self 156 OP
15/09/09 11:11:04 INFO exec.ListSinkOperator: Operator 156 OP initialized
15/09/09 11:11:04 INFO exec.ListSinkOperator: Initialization Done 156 OP
15/09/09 11:11:04 INFO ql.Driver: Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:tab_name, type:string, comment:from deserializer)], properties:null)
15/09/09 11:11:04 INFO log.PerfLogger: </PERFLOG method=compile start=1441815064884 end=1441815064888 duration=4 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:04 INFO log.PerfLogger: <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:04 INFO ql.Driver: Starting command: SHOW TABLES
15/09/09 11:11:04 INFO log.PerfLogger: </PERFLOG method=TimeToSubmit start=1441815064884 end=1441815064888 duration=4 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:04 INFO log.PerfLogger: <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:04 INFO log.PerfLogger: <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:04 INFO metastore.HiveMetaStore: 0: get_database: default
15/09/09 11:11:04 INFO HiveMetaStore.audit: ugi=hpatel	ip=unknown-ip-addr	cmd=get_database: default	
15/09/09 11:11:04 INFO metastore.HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
15/09/09 11:11:04 INFO metastore.ObjectStore: ObjectStore, initialize called
15/09/09 11:11:04 INFO DataNucleus.Persistence: Property datanucleus.cache.level2 unknown - will be ignored
15/09/09 11:11:04 INFO DataNucleus.Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
15/09/09 11:11:05 INFO metastore.ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
15/09/09 11:11:05 INFO metastore.MetaStoreDirectSql: MySQL check failed, assuming we are not on mysql: unknown token: 
15/09/09 11:11:05 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
15/09/09 11:11:05 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
15/09/09 11:11:05 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
15/09/09 11:11:05 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
15/09/09 11:11:05 INFO metastore.ObjectStore: Initialized ObjectStore
15/09/09 11:11:05 ERROR metastore.RetryingHMSHandler: NoSuchObjectException(message:There is no database named default)
	at org.apache.hadoop.hive.metastore.ObjectStore.getMDatabase(ObjectStore.java:516)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabase(ObjectStore.java:527)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:108)
	at com.sun.proxy.$Proxy11.getDatabase(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_database(HiveMetaStore.java:805)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:106)
	at com.sun.proxy.$Proxy17.get_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getDatabase(HiveMetaStoreClient.java:960)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:90)
	at com.sun.proxy.$Proxy18.getDatabase(Unknown Source)
	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1189)
	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1178)
	at org.apache.hadoop.hive.ql.exec.DDLTask.showTables(DDLTask.java:2485)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:369)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:153)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:85)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1554)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1321)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1139)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:962)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:952)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:197)
	at com.klarna.hiverunner.HiveServerContainer.pingHiveServer(HiveServerContainer.java:147)
	at com.klarna.hiverunner.HiveServerContainer.init(HiveServerContainer.java:74)
	at com.klarna.hiverunner.builder.HiveShellBase.start(HiveShellBase.java:96)
	at com.klarna.hiverunner.ResourceOutputStreamTest.sequenceFile(ResourceOutputStreamTest.java:66)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at com.klarna.hiverunner.StandaloneHiveRunner.evaluateStatement(StandaloneHiveRunner.java:100)
	at com.klarna.hiverunner.StandaloneHiveRunner.access$000(StandaloneHiveRunner.java:53)
	at com.klarna.hiverunner.StandaloneHiveRunner$1$1.evaluate(StandaloneHiveRunner.java:79)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:64)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:50)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)
	at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)
	at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:360)
	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54)
	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

15/09/09 11:11:05 ERROR exec.DDLTask: org.apache.hadoop.hive.ql.metadata.HiveException: Database does not exist: default
	at org.apache.hadoop.hive.ql.exec.DDLTask.showTables(DDLTask.java:2486)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:369)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:153)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:85)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1554)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1321)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1139)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:962)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:952)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:197)
	at com.klarna.hiverunner.HiveServerContainer.pingHiveServer(HiveServerContainer.java:147)
	at com.klarna.hiverunner.HiveServerContainer.init(HiveServerContainer.java:74)
	at com.klarna.hiverunner.builder.HiveShellBase.start(HiveShellBase.java:96)
	at com.klarna.hiverunner.ResourceOutputStreamTest.sequenceFile(ResourceOutputStreamTest.java:66)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at com.klarna.hiverunner.StandaloneHiveRunner.evaluateStatement(StandaloneHiveRunner.java:100)
	at com.klarna.hiverunner.StandaloneHiveRunner.access$000(StandaloneHiveRunner.java:53)
	at com.klarna.hiverunner.StandaloneHiveRunner$1$1.evaluate(StandaloneHiveRunner.java:79)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:64)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:50)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)
	at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)
	at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:360)
	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54)
	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Database does not exist: default
15/09/09 11:11:05 ERROR ql.Driver: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Database does not exist: default
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=Driver.execute start=1441815064888 end=1441815065047 duration=159 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=releaseLocks start=1441815065047 end=1441815065047 duration=0 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 ERROR hiverunner.StandaloneHiveRunner: Failed to ping HiveServer: Query returned non-zero code: 1, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Database does not exist: default
java.lang.IllegalStateException: Failed to ping HiveServer: Query returned non-zero code: 1, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Database does not exist: default
	at com.klarna.hiverunner.HiveServerContainer.pingHiveServer(HiveServerContainer.java:149)
	at com.klarna.hiverunner.HiveServerContainer.init(HiveServerContainer.java:74)
	at com.klarna.hiverunner.builder.HiveShellBase.start(HiveShellBase.java:96)
	at com.klarna.hiverunner.ResourceOutputStreamTest.sequenceFile(ResourceOutputStreamTest.java:66)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at com.klarna.hiverunner.StandaloneHiveRunner.evaluateStatement(StandaloneHiveRunner.java:100)
	at com.klarna.hiverunner.StandaloneHiveRunner.access$000(StandaloneHiveRunner.java:53)
	at com.klarna.hiverunner.StandaloneHiveRunner$1$1.evaluate(StandaloneHiveRunner.java:79)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:64)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:50)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)
	at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)
	at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:360)
	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54)
	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: HiveServerException(message:Query returned non-zero code: 1, cause: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Database does not exist: default, errorCode:1, SQLState:08S01)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:218)
	at com.klarna.hiverunner.HiveServerContainer.pingHiveServer(HiveServerContainer.java:147)
	... 51 more
15/09/09 11:11:05 INFO service.HiveServer: Running the query: USE default
15/09/09 11:11:05 INFO exec.ListSinkOperator: 156 finished. closing... 
15/09/09 11:11:05 INFO exec.ListSinkOperator: 156 Close done
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO ql.Driver: Concurrency mode is disabled, not creating a lock manager
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO parse.ParseDriver: Parsing command: USE default
15/09/09 11:11:05 INFO parse.ParseDriver: Parse Completed
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=parse start=1441815065049 end=1441815065049 duration=0 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO ql.Driver: Semantic Analysis Completed
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=semanticAnalyze start=1441815065049 end=1441815065049 duration=0 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=compile start=1441815065048 end=1441815065049 duration=1 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO ql.Driver: Starting command: USE default
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=TimeToSubmit start=1441815065048 end=1441815065049 duration=1 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO metastore.HiveMetaStore: 0: get_database: default
15/09/09 11:11:05 INFO HiveMetaStore.audit: ugi=hpatel	ip=unknown-ip-addr	cmd=get_database: default	
15/09/09 11:11:05 ERROR metastore.RetryingHMSHandler: NoSuchObjectException(message:There is no database named default)
	at org.apache.hadoop.hive.metastore.ObjectStore.getMDatabase(ObjectStore.java:516)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabase(ObjectStore.java:527)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:108)
	at com.sun.proxy.$Proxy11.getDatabase(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_database(HiveMetaStore.java:805)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:106)
	at com.sun.proxy.$Proxy17.get_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getDatabase(HiveMetaStoreClient.java:960)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:90)
	at com.sun.proxy.$Proxy18.getDatabase(Unknown Source)
	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1189)
	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1178)
	at org.apache.hadoop.hive.ql.exec.DDLTask.switchDatabase(DDLTask.java:4054)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:270)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:153)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:85)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1554)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1321)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1139)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:962)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:952)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:197)
	at com.klarna.hiverunner.HiveServerContainer.tearDown(HiveServerContainer.java:119)
	at com.klarna.hiverunner.builder.HiveShellTearable.tearDown(HiveShellTearable.java:41)
	at com.klarna.hiverunner.StandaloneHiveRunner.evaluateStatement(StandaloneHiveRunner.java:106)
	at com.klarna.hiverunner.StandaloneHiveRunner.access$000(StandaloneHiveRunner.java:53)
	at com.klarna.hiverunner.StandaloneHiveRunner$1$1.evaluate(StandaloneHiveRunner.java:79)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:64)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:50)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)
	at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)
	at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:360)
	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54)
	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

15/09/09 11:11:05 ERROR exec.DDLTask: org.apache.hadoop.hive.ql.metadata.HiveException: Database does not exist: default
	at org.apache.hadoop.hive.ql.exec.DDLTask.switchDatabase(DDLTask.java:4055)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:270)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:153)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:85)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1554)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1321)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1139)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:962)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:952)
	at org.apache.hadoop.hive.service.HiveServer$HiveServerHandler.execute(HiveServer.java:197)
	at com.klarna.hiverunner.HiveServerContainer.tearDown(HiveServerContainer.java:119)
	at com.klarna.hiverunner.builder.HiveShellTearable.tearDown(HiveShellTearable.java:41)
	at com.klarna.hiverunner.StandaloneHiveRunner.evaluateStatement(StandaloneHiveRunner.java:106)
	at com.klarna.hiverunner.StandaloneHiveRunner.access$000(StandaloneHiveRunner.java:53)
	at com.klarna.hiverunner.StandaloneHiveRunner$1$1.evaluate(StandaloneHiveRunner.java:79)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:64)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:50)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)
	at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)
	at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:360)
	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54)
	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Database does not exist: default
15/09/09 11:11:05 ERROR ql.Driver: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Database does not exist: default
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=Driver.execute start=1441815065049 end=1441815065052 duration=3 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=releaseLocks start=1441815065052 end=1441815065052 duration=0 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO metastore.HiveMetaStore: 0: Shutting down the object store...
15/09/09 11:11:05 INFO HiveMetaStore.audit: ugi=hpatel	ip=unknown-ip-addr	cmd=Shutting down the object store...	
15/09/09 11:11:05 INFO metastore.HiveMetaStore: 0: Metastore shutdown complete.
15/09/09 11:11:05 INFO HiveMetaStore.audit: ugi=hpatel	ip=unknown-ip-addr	cmd=Metastore shutdown complete.	
15/09/09 11:11:05 INFO hiverunner.HiveServerContainer: Tore down HiveServer instance
15/09/09 11:11:05 INFO metastore.HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
15/09/09 11:11:05 INFO metastore.ObjectStore: ObjectStore, initialize called
15/09/09 11:11:05 INFO DataNucleus.Persistence: Property datanucleus.cache.level2 unknown - will be ignored
15/09/09 11:11:05 INFO DataNucleus.Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
15/09/09 11:11:05 INFO metastore.ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
15/09/09 11:11:05 INFO metastore.MetaStoreDirectSql: MySQL check failed, assuming we are not on mysql: unknown token: 
15/09/09 11:11:05 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
15/09/09 11:11:05 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
15/09/09 11:11:05 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
15/09/09 11:11:05 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
15/09/09 11:11:05 INFO metastore.ObjectStore: Initialized ObjectStore
15/09/09 11:11:05 INFO metastore.HiveMetaStore: No user is added in admin role, since config is empty
15/09/09 11:11:05 INFO metastore.HiveMetaStore: 0: Shutting down the object store...
15/09/09 11:11:05 INFO HiveMetaStore.audit: ugi=hpatel	ip=unknown-ip-addr	cmd=Shutting down the object store...	
15/09/09 11:11:05 INFO metastore.HiveMetaStore: 0: Metastore shutdown complete.
15/09/09 11:11:05 INFO HiveMetaStore.audit: ugi=hpatel	ip=unknown-ip-addr	cmd=Metastore shutdown complete.	
15/09/09 11:11:05 INFO metastore.HiveMetaStore: No user is added in admin role, since config is empty
15/09/09 11:11:05 INFO session.SessionState: No Tez session required at this point. hive.execution.engine=mr.
15/09/09 11:11:05 INFO service.HiveServer: Putting temp output to file /var/folders/y7/4_pz5fzx54ngcmghz3v6t3m00000gn/T/junit5336729344851497648/localscratchdir/d48a777b-5ab5-483a-950e-7febcf822f4c3865483398680245233.pipeout
15/09/09 11:11:05 INFO service.HiveServer: Running the query: SHOW TABLES
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO ql.Driver: Concurrency mode is disabled, not creating a lock manager
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO parse.ParseDriver: Parsing command: SHOW TABLES
15/09/09 11:11:05 INFO parse.ParseDriver: Parse Completed
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=parse start=1441815065237 end=1441815065237 duration=0 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO ql.Driver: Semantic Analysis Completed
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=semanticAnalyze start=1441815065237 end=1441815065241 duration=4 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO exec.ListSinkOperator: Initializing Self 157 OP
15/09/09 11:11:05 INFO exec.ListSinkOperator: Operator 157 OP initialized
15/09/09 11:11:05 INFO exec.ListSinkOperator: Initialization Done 157 OP
15/09/09 11:11:05 INFO ql.Driver: Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:tab_name, type:string, comment:from deserializer)], properties:null)
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=compile start=1441815065237 end=1441815065242 duration=5 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO ql.Driver: Starting command: SHOW TABLES
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=TimeToSubmit start=1441815065237 end=1441815065242 duration=5 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO metastore.HiveMetaStore: 0: get_database: default
15/09/09 11:11:05 INFO HiveMetaStore.audit: ugi=hpatel	ip=unknown-ip-addr	cmd=get_database: default	
15/09/09 11:11:05 INFO metastore.HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
15/09/09 11:11:05 INFO metastore.ObjectStore: ObjectStore, initialize called
15/09/09 11:11:05 INFO metastore.MetaStoreDirectSql: MySQL check failed, assuming we are not on mysql: unknown token: 
15/09/09 11:11:05 INFO DataNucleus.Query: Reading in results for query "org.datanucleus.store.rdbms.query.SQLQuery@0" since the connection used is closing
15/09/09 11:11:05 INFO metastore.ObjectStore: Initialized ObjectStore
15/09/09 11:11:05 INFO metastore.HiveMetaStore: 0: get_tables: db=default pat=.*
15/09/09 11:11:05 INFO HiveMetaStore.audit: ugi=hpatel	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=runTasks start=1441815065242 end=1441815065251 duration=9 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=Driver.execute start=1441815065242 end=1441815065251 duration=9 from=org.apache.hadoop.hive.ql.Driver>
OK
15/09/09 11:11:05 INFO ql.Driver: OK
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=releaseLocks start=1441815065251 end=1441815065251 duration=0 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=Driver.run start=1441815065237 end=1441815065251 duration=14 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO builder.HiveShellTearable: Created hive resource /var/folders/y7/4_pz5fzx54ngcmghz3v6t3m00000gn/T/junit5336729344851497648/hadooptmp/baz/foo.bar
15/09/09 11:11:05 INFO service.HiveServer: Running the query: USE default
15/09/09 11:11:05 INFO exec.ListSinkOperator: 157 finished. closing... 
15/09/09 11:11:05 INFO exec.ListSinkOperator: 157 Close done
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO ql.Driver: Concurrency mode is disabled, not creating a lock manager
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO parse.ParseDriver: Parsing command: USE default
15/09/09 11:11:05 INFO parse.ParseDriver: Parse Completed
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=parse start=1441815065253 end=1441815065253 duration=0 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO ql.Driver: Semantic Analysis Completed
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=semanticAnalyze start=1441815065253 end=1441815065253 duration=0 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=compile start=1441815065252 end=1441815065253 duration=1 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO ql.Driver: Starting command: USE default
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=TimeToSubmit start=1441815065252 end=1441815065253 duration=1 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO metastore.HiveMetaStore: 0: get_database: default
15/09/09 11:11:05 INFO HiveMetaStore.audit: ugi=hpatel	ip=unknown-ip-addr	cmd=get_database: default	
15/09/09 11:11:05 INFO metastore.HiveMetaStore: 0: get_database: default
15/09/09 11:11:05 INFO HiveMetaStore.audit: ugi=hpatel	ip=unknown-ip-addr	cmd=get_database: default	
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=runTasks start=1441815065253 end=1441815065256 duration=3 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=Driver.execute start=1441815065253 end=1441815065256 duration=3 from=org.apache.hadoop.hive.ql.Driver>
OK
15/09/09 11:11:05 INFO ql.Driver: OK
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=releaseLocks start=1441815065256 end=1441815065256 duration=0 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=Driver.run start=1441815065252 end=1441815065256 duration=4 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO metastore.HiveMetaStore: 0: Shutting down the object store...
15/09/09 11:11:05 INFO HiveMetaStore.audit: ugi=hpatel	ip=unknown-ip-addr	cmd=Shutting down the object store...	
15/09/09 11:11:05 INFO metastore.HiveMetaStore: 0: Metastore shutdown complete.
15/09/09 11:11:05 INFO HiveMetaStore.audit: ugi=hpatel	ip=unknown-ip-addr	cmd=Metastore shutdown complete.	
15/09/09 11:11:05 INFO hiverunner.HiveServerContainer: Tore down HiveServer instance
15/09/09 11:11:05 INFO metastore.HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
15/09/09 11:11:05 INFO metastore.ObjectStore: ObjectStore, initialize called
15/09/09 11:11:05 INFO DataNucleus.Persistence: Property datanucleus.cache.level2 unknown - will be ignored
15/09/09 11:11:05 INFO DataNucleus.Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
15/09/09 11:11:05 INFO metastore.ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
15/09/09 11:11:05 INFO metastore.MetaStoreDirectSql: MySQL check failed, assuming we are not on mysql: unknown token: 
15/09/09 11:11:05 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
15/09/09 11:11:05 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
15/09/09 11:11:05 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
15/09/09 11:11:05 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
15/09/09 11:11:05 INFO metastore.ObjectStore: Initialized ObjectStore
15/09/09 11:11:05 INFO metastore.HiveMetaStore: No user is added in admin role, since config is empty
15/09/09 11:11:05 INFO metastore.HiveMetaStore: 0: Shutting down the object store...
15/09/09 11:11:05 INFO HiveMetaStore.audit: ugi=hpatel	ip=unknown-ip-addr	cmd=Shutting down the object store...	
15/09/09 11:11:05 INFO metastore.HiveMetaStore: 0: Metastore shutdown complete.
15/09/09 11:11:05 INFO HiveMetaStore.audit: ugi=hpatel	ip=unknown-ip-addr	cmd=Metastore shutdown complete.	
15/09/09 11:11:05 INFO metastore.HiveMetaStore: No user is added in admin role, since config is empty
15/09/09 11:11:05 INFO session.SessionState: No Tez session required at this point. hive.execution.engine=mr.
15/09/09 11:11:05 INFO service.HiveServer: Putting temp output to file /var/folders/y7/4_pz5fzx54ngcmghz3v6t3m00000gn/T/junit4702952165200405140/localscratchdir/bb717cd6-4380-4e07-a426-3eeff22276da4095542333300050348.pipeout
15/09/09 11:11:05 INFO service.HiveServer: Running the query: SHOW TABLES
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO ql.Driver: Concurrency mode is disabled, not creating a lock manager
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO parse.ParseDriver: Parsing command: SHOW TABLES
15/09/09 11:11:05 INFO parse.ParseDriver: Parse Completed
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=parse start=1441815065432 end=1441815065432 duration=0 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO ql.Driver: Semantic Analysis Completed
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=semanticAnalyze start=1441815065432 end=1441815065446 duration=14 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO exec.ListSinkOperator: Initializing Self 158 OP
15/09/09 11:11:05 INFO exec.ListSinkOperator: Operator 158 OP initialized
15/09/09 11:11:05 INFO exec.ListSinkOperator: Initialization Done 158 OP
15/09/09 11:11:05 INFO ql.Driver: Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:tab_name, type:string, comment:from deserializer)], properties:null)
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=compile start=1441815065432 end=1441815065447 duration=15 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO ql.Driver: Starting command: SHOW TABLES
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=TimeToSubmit start=1441815065432 end=1441815065447 duration=15 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO metastore.HiveMetaStore: 0: get_database: default
15/09/09 11:11:05 INFO HiveMetaStore.audit: ugi=hpatel	ip=unknown-ip-addr	cmd=get_database: default	
15/09/09 11:11:05 INFO metastore.HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
15/09/09 11:11:05 INFO metastore.ObjectStore: ObjectStore, initialize called
15/09/09 11:11:05 INFO metastore.MetaStoreDirectSql: MySQL check failed, assuming we are not on mysql: unknown token: 
15/09/09 11:11:05 INFO DataNucleus.Query: Reading in results for query "org.datanucleus.store.rdbms.query.SQLQuery@0" since the connection used is closing
15/09/09 11:11:05 INFO metastore.ObjectStore: Initialized ObjectStore
15/09/09 11:11:05 INFO metastore.HiveMetaStore: 0: get_tables: db=default pat=.*
15/09/09 11:11:05 INFO HiveMetaStore.audit: ugi=hpatel	ip=unknown-ip-addr	cmd=get_tables: db=default pat=.*	
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=runTasks start=1441815065447 end=1441815065456 duration=9 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=Driver.execute start=1441815065447 end=1441815065456 duration=9 from=org.apache.hadoop.hive.ql.Driver>
OK
15/09/09 11:11:05 INFO ql.Driver: OK
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=releaseLocks start=1441815065456 end=1441815065456 duration=0 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=Driver.run start=1441815065432 end=1441815065456 duration=24 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO builder.HiveShellTearable: Executing script: create table foobar(str string) location '${hiveconf:hadoop.tmp.dir.uri}/baz'
15/09/09 11:11:05 INFO service.HiveServer: Running the query: create table foobar(str string) location '${hiveconf:hadoop.tmp.dir.uri}/baz'
15/09/09 11:11:05 INFO exec.ListSinkOperator: 158 finished. closing... 
15/09/09 11:11:05 INFO exec.ListSinkOperator: 158 Close done
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO ql.Driver: Concurrency mode is disabled, not creating a lock manager
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO parse.ParseDriver: Parsing command: create table foobar(str string) location 'file:///var/folders/y7/4_pz5fzx54ngcmghz3v6t3m00000gn/T/junit4702952165200405140/hadooptmp//baz'
15/09/09 11:11:05 INFO parse.ParseDriver: Parse Completed
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=parse start=1441815065457 end=1441815065457 duration=0 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO parse.SemanticAnalyzer: Starting Semantic Analysis
15/09/09 11:11:05 INFO parse.SemanticAnalyzer: Creating table foobar position=13
15/09/09 11:11:05 INFO metastore.HiveMetaStore: 0: get_database: default
15/09/09 11:11:05 INFO HiveMetaStore.audit: ugi=hpatel	ip=unknown-ip-addr	cmd=get_database: default	
15/09/09 11:11:05 INFO ql.Driver: Semantic Analysis Completed
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=semanticAnalyze start=1441815065457 end=1441815065459 duration=2 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=compile start=1441815065457 end=1441815065459 duration=2 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO ql.Driver: Starting command: create table foobar(str string) location 'file:///var/folders/y7/4_pz5fzx54ngcmghz3v6t3m00000gn/T/junit4702952165200405140/hadooptmp//baz'
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=TimeToSubmit start=1441815065457 end=1441815065459 duration=2 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO metastore.HiveMetaStore: 0: create_table: Table(tableName:foobar, dbName:default, owner:hpatel, createTime:1441815065, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:str, type:string, comment:null)], location:file:/var/folders/y7/4_pz5fzx54ngcmghz3v6t3m00000gn/T/junit4702952165200405140/hadooptmp/baz, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE)
15/09/09 11:11:05 INFO HiveMetaStore.audit: ugi=hpatel	ip=unknown-ip-addr	cmd=create_table: Table(tableName:foobar, dbName:default, owner:hpatel, createTime:1441815065, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:str, type:string, comment:null)], location:file:/var/folders/y7/4_pz5fzx54ngcmghz3v6t3m00000gn/T/junit4702952165200405140/hadooptmp/baz, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE)	
15/09/09 11:11:05 WARN metastore.HiveMetaStore: Location: file:/var/folders/y7/4_pz5fzx54ngcmghz3v6t3m00000gn/T/junit4702952165200405140/hadooptmp/baz specified for non-external table:foobar
15/09/09 11:11:05 INFO common.FileUtils: Creating directory if it doesn't exist: file:/var/folders/y7/4_pz5fzx54ngcmghz3v6t3m00000gn/T/junit4702952165200405140/hadooptmp/baz
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=runTasks start=1441815065459 end=1441815065498 duration=39 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=Driver.execute start=1441815065459 end=1441815065498 duration=39 from=org.apache.hadoop.hive.ql.Driver>
OK
15/09/09 11:11:05 INFO ql.Driver: OK
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=releaseLocks start=1441815065499 end=1441815065499 duration=0 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=Driver.run start=1441815065457 end=1441815065499 duration=42 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO builder.HiveShellTearable: Created hive resource /var/folders/y7/4_pz5fzx54ngcmghz3v6t3m00000gn/T/junit4702952165200405140/hadooptmp/baz/foo.bar
15/09/09 11:11:05 INFO service.HiveServer: Running the query: select * from foobar
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO ql.Driver: Concurrency mode is disabled, not creating a lock manager
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO parse.ParseDriver: Parsing command: select * from foobar
15/09/09 11:11:05 INFO parse.ParseDriver: Parse Completed
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=parse start=1441815065499 end=1441815065500 duration=1 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO parse.SemanticAnalyzer: Starting Semantic Analysis
15/09/09 11:11:05 INFO parse.SemanticAnalyzer: Completed phase 1 of Semantic Analysis
15/09/09 11:11:05 INFO parse.SemanticAnalyzer: Get metadata for source tables
15/09/09 11:11:05 INFO metastore.HiveMetaStore: 0: get_table : db=default tbl=foobar
15/09/09 11:11:05 INFO HiveMetaStore.audit: ugi=hpatel	ip=unknown-ip-addr	cmd=get_table : db=default tbl=foobar	
15/09/09 11:11:05 INFO parse.SemanticAnalyzer: Get metadata for subqueries
15/09/09 11:11:05 INFO parse.SemanticAnalyzer: Get metadata for destination tables
15/09/09 11:11:05 INFO ql.Context: New scratch dir is file:/var/folders/y7/4_pz5fzx54ngcmghz3v6t3m00000gn/T/junit4702952165200405140/scratchdir/hive_2015-09-09_11-11-05_499_1758579769559722737-1
15/09/09 11:11:05 INFO parse.SemanticAnalyzer: Completed getting MetaData in Semantic Analysis
15/09/09 11:11:05 INFO common.FileUtils: Creating directory if it doesn't exist: file:/var/folders/y7/4_pz5fzx54ngcmghz3v6t3m00000gn/T/junit4702952165200405140/scratchdir/hive_2015-09-09_11-11-05_499_1758579769559722737-1/-mr-10000/.hive-staging_hive_2015-09-09_11-11-05_499_1758579769559722737-1
15/09/09 11:11:05 INFO parse.SemanticAnalyzer: Set stats collection dir : file:/var/folders/y7/4_pz5fzx54ngcmghz3v6t3m00000gn/T/junit4702952165200405140/scratchdir/hive_2015-09-09_11-11-05_499_1758579769559722737-1/-mr-10000/.hive-staging_hive_2015-09-09_11-11-05_499_1758579769559722737-1/-ext-10002
15/09/09 11:11:05 INFO ppd.OpProcFactory: Processing for FS(161)
15/09/09 11:11:05 INFO ppd.OpProcFactory: Processing for SEL(160)
15/09/09 11:11:05 INFO ppd.OpProcFactory: Processing for TS(159)
15/09/09 11:11:05 INFO parse.SemanticAnalyzer: Completed plan generation
15/09/09 11:11:05 INFO ql.Driver: Semantic Analysis Completed
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=semanticAnalyze start=1441815065500 end=1441815065540 duration=40 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO exec.TableScanOperator: Initializing Self 159 TS
15/09/09 11:11:05 INFO exec.TableScanOperator: Operator 159 TS initialized
15/09/09 11:11:05 INFO exec.TableScanOperator: Initializing children of 159 TS
15/09/09 11:11:05 INFO exec.SelectOperator: Initializing child 160 SEL
15/09/09 11:11:05 INFO exec.SelectOperator: Initializing Self 160 SEL
15/09/09 11:11:05 INFO exec.SelectOperator: SELECT struct<str:string>
15/09/09 11:11:05 INFO exec.SelectOperator: Operator 160 SEL initialized
15/09/09 11:11:05 INFO exec.SelectOperator: Initializing children of 160 SEL
15/09/09 11:11:05 INFO exec.ListSinkOperator: Initializing child 162 OP
15/09/09 11:11:05 INFO exec.ListSinkOperator: Initializing Self 162 OP
15/09/09 11:11:05 INFO exec.ListSinkOperator: Operator 162 OP initialized
15/09/09 11:11:05 INFO exec.ListSinkOperator: Initialization Done 162 OP
15/09/09 11:11:05 INFO exec.SelectOperator: Initialization Done 160 SEL
15/09/09 11:11:05 INFO exec.TableScanOperator: Initialization Done 159 TS
15/09/09 11:11:05 INFO ql.Driver: Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:foobar.str, type:string, comment:null)], properties:null)
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=compile start=1441815065499 end=1441815065541 duration=42 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO ql.Driver: Starting command: select * from foobar
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=TimeToSubmit start=1441815065499 end=1441815065541 duration=42 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=runTasks start=1441815065541 end=1441815065541 duration=0 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=Driver.execute start=1441815065541 end=1441815065541 duration=0 from=org.apache.hadoop.hive.ql.Driver>
OK
15/09/09 11:11:05 INFO ql.Driver: OK
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=releaseLocks start=1441815065541 end=1441815065541 duration=0 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=Driver.run start=1441815065499 end=1441815065541 duration=42 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO mapred.FileInputFormat: Total input paths to process : 1
15/09/09 11:11:05 INFO service.HiveServer: Running the query: USE default
15/09/09 11:11:05 INFO exec.TableScanOperator: 159 finished. closing... 
15/09/09 11:11:05 INFO exec.SelectOperator: 160 finished. closing... 
15/09/09 11:11:05 INFO exec.ListSinkOperator: 162 finished. closing... 
15/09/09 11:11:05 INFO exec.ListSinkOperator: 162 Close done
15/09/09 11:11:05 INFO exec.SelectOperator: 160 Close done
15/09/09 11:11:05 INFO exec.TableScanOperator: 159 Close done
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO ql.Driver: Concurrency mode is disabled, not creating a lock manager
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO parse.ParseDriver: Parsing command: USE default
15/09/09 11:11:05 INFO parse.ParseDriver: Parse Completed
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=parse start=1441815065543 end=1441815065543 duration=0 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO ql.Driver: Semantic Analysis Completed
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=semanticAnalyze start=1441815065543 end=1441815065544 duration=1 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=compile start=1441815065543 end=1441815065544 duration=1 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO ql.Driver: Starting command: USE default
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=TimeToSubmit start=1441815065543 end=1441815065544 duration=1 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO metastore.HiveMetaStore: 0: get_database: default
15/09/09 11:11:05 INFO HiveMetaStore.audit: ugi=hpatel	ip=unknown-ip-addr	cmd=get_database: default	
15/09/09 11:11:05 INFO metastore.HiveMetaStore: 0: get_database: default
15/09/09 11:11:05 INFO HiveMetaStore.audit: ugi=hpatel	ip=unknown-ip-addr	cmd=get_database: default	
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=runTasks start=1441815065544 end=1441815065546 duration=2 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=Driver.execute start=1441815065544 end=1441815065547 duration=3 from=org.apache.hadoop.hive.ql.Driver>
OK
15/09/09 11:11:05 INFO ql.Driver: OK
15/09/09 11:11:05 INFO log.PerfLogger: <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=releaseLocks start=1441815065547 end=1441815065547 duration=0 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO log.PerfLogger: </PERFLOG method=Driver.run start=1441815065543 end=1441815065547 duration=4 from=org.apache.hadoop.hive.ql.Driver>
15/09/09 11:11:05 INFO metastore.HiveMetaStore: 0: Shutting down the object store...
15/09/09 11:11:05 INFO HiveMetaStore.audit: ugi=hpatel	ip=unknown-ip-addr	cmd=Shutting down the object store...	
15/09/09 11:11:05 INFO metastore.HiveMetaStore: 0: Metastore shutdown complete.
15/09/09 11:11:05 INFO HiveMetaStore.audit: ugi=hpatel	ip=unknown-ip-addr	cmd=Metastore shutdown complete.	
15/09/09 11:11:05 INFO hiverunner.HiveServerContainer: Tore down HiveServer instance
]]></system-err>
</testsuite>
